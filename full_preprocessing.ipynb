{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42288c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadr\n",
    "import yaml\n",
    "\n",
    "### WARNING: Running cells in this jupyter notebook at random wil overwrite data files. Run all once, then proceed with caution.\n",
    "\n",
    "# That said, run this cell first to load the config. Reload this cell to reload config.\n",
    "config = yaml.load(open('config.yaml', 'r'), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94db8878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATES DATASET\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Optional, Sequence\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _safe_write(df: pd.DataFrame, out_path: Path) -> None:\n",
    "    \"\"\"\n",
    "    Write a window file in a \"fast\" format if possible (Parquet),\n",
    "    otherwise fall back to compressed CSV.\n",
    "    \"\"\"\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(out_path.with_suffix(\".csv\"), index=False)\n",
    "\n",
    "\n",
    "def create_timeseries_windows_dataset(\n",
    "    dataset_path: str | Path,\n",
    "    window_months_list: Sequence[int] = (12, 6, 3),\n",
    "    out_root: str | Path = \"data_windows_fast\",\n",
    "    time_col: str = \"utc\",\n",
    "    sort: bool = True,\n",
    "    recursive: bool = True,\n",
    "    require_full_window: bool = True,\n",
    "    keep_cols: Optional[Iterable[str]] = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Build a new dataset of time-series windows from CSV files.\n",
    "\n",
    "    - Reads each CSV in dataset_path (default: recursive).\n",
    "    - Splits each file into consecutive windows of length window_months.\n",
    "    - Saves each window as a separate file under:\n",
    "        out_root/{window_months}m/\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_path : folder containing CSVs (e.g. \"data_csv\")\n",
    "    window_months_list : e.g. (12,6,3)\n",
    "    out_root : output folder\n",
    "    time_col : timestamp column name in the CSV (e.g. \"utc\")\n",
    "    require_full_window : if True, only windows that fully fit are saved\n",
    "                          if False, the final partial window is also saved\n",
    "    keep_cols : optionally restrict columns saved (e.g. [\"utc\",\"min\",\"max\"])\n",
    "                if None, saves all columns\n",
    "    \"\"\"\n",
    "    dataset_path = Path.cwd() / config[\"data_preparation\"][\"raw_dataset_csv\"]\n",
    "    out_root = Path.cwd() / config[\"data_preparation\"][\"windowed_dataset\"]\n",
    "\n",
    "    pattern = \"**/*.csv\" if recursive else \"*.csv\"\n",
    "    csv_files = sorted(dataset_path.glob(pattern))\n",
    "\n",
    "    print(f\"[INFO] dataset_path={dataset_path.resolve()}\")\n",
    "    print(f\"[INFO] out_root={out_root.resolve()}\")\n",
    "    print(f\"[INFO] found {len(csv_files)} CSV files\")\n",
    "\n",
    "    if not csv_files:\n",
    "        return\n",
    "\n",
    "    for months in window_months_list:\n",
    "        (out_root / f\"{months}m\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for i, csv_path in enumerate(csv_files, 1):\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "\n",
    "            if time_col not in df.columns:\n",
    "                print(f\"[SKIP] {csv_path} (missing '{time_col}')\")\n",
    "                continue\n",
    "\n",
    "            df[time_col] = pd.to_datetime(df[time_col], errors=\"coerce\", utc=False)\n",
    "            df = df.dropna(subset=[time_col])\n",
    "\n",
    "            if df.empty:\n",
    "                print(f\"[SKIP] {csv_path} (no valid timestamps)\")\n",
    "                continue\n",
    "\n",
    "            if sort:\n",
    "                df = df.sort_values(time_col)\n",
    "\n",
    "            if keep_cols is not None:\n",
    "                keep_cols = list(keep_cols)\n",
    "                # Always keep time_col\n",
    "                if time_col not in keep_cols:\n",
    "                    keep_cols = [time_col] + keep_cols\n",
    "                existing = [c for c in keep_cols if c in df.columns]\n",
    "                df = df[existing]\n",
    "\n",
    "            t0 = df[time_col].iloc[0]\n",
    "            tN = df[time_col].iloc[-1]\n",
    "\n",
    "            rel = csv_path.relative_to(dataset_path)\n",
    "            base_stem = rel.with_suffix(\"\")  # preserves subfolders and stem\n",
    "\n",
    "            for months in window_months_list:\n",
    "                out_dir = out_root / f\"{months}m\" / base_stem.parent\n",
    "                out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                start = t0\n",
    "                win_idx = 0\n",
    "\n",
    "                while True:\n",
    "                    end = start + pd.DateOffset(months=int(months))\n",
    "\n",
    "                    if require_full_window and end > tN:\n",
    "                        break\n",
    "\n",
    "                    # if not require_full_window, allow last partial window\n",
    "                    if (not require_full_window) and (start > tN):\n",
    "                        break\n",
    "\n",
    "                    # slice: [start, end)\n",
    "                    if require_full_window:\n",
    "                        w = df[(df[time_col] >= start) & (df[time_col] < end)]\n",
    "                    else:\n",
    "                        w = df[(df[time_col] >= start) & (df[time_col] < min(end, tN))]\n",
    "\n",
    "                    # If a window ends up empty (e.g. gaps), skip it\n",
    "                    if not w.empty:\n",
    "                        out_name = f\"{base_stem.name}_{start:%Y%m%d}{end:%Y%m%d}__w{win_idx:04d}\"\n",
    "                        out_path = out_dir / out_name\n",
    "                        _safe_write(w, out_path)\n",
    "\n",
    "                    win_idx += 1\n",
    "                    start = end\n",
    "\n",
    "            if i % 50 == 0:\n",
    "                print(f\"[INFO] processed {i}/{len(csv_files)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERR] {csv_path}: {e}\")\n",
    "\n",
    "    print(\"[DONE] Windowed dataset created.\")\n",
    "\n",
    "create_timeseries_windows_dataset(\n",
    "    dataset_path=\"data_csv\",\n",
    "    window_months_list=(12, 6, 3),\n",
    "    out_root=\"data_windows_fast\",\n",
    "    time_col=\"utc\",\n",
    "    recursive=True,\n",
    "    require_full_window=True,\n",
    "    # keep_cols=[\"utc\", \"min\", \"max\"]  # optional: keep only these columns\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
