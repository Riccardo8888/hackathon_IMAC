{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from dataclasses import asdict\n",
    "from datetime import time\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from core.wavenet import WaveNetCategorical\n",
    "from util.metrics import save_random_postcue_plots\n",
    "from util.util import *\n",
    "from util.datasets import RandomWaveNetSegments\n",
    "from util.Cfg import Cfg\n",
    "from util.wavenet import dilations_1s_context, receptive_field\n",
    "from core.training import train_model, eval_streaming_latency_comp, eval_postcue_window\n",
    "\n",
    "import yaml\n",
    "\n",
    "config = yaml.safe_load(open(\"config.yaml\"))\n",
    "\n",
    "def main():\n",
    "    print(\"RUNNING FILE:\", Path(__file__).resolve())\n",
    "\n",
    "    args = Cfg()\n",
    "\n",
    "    if args.eval_only:\n",
    "        os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "    out_dir = Path(args.out_dir)\n",
    "    logger = setup_logger(out_dir)\n",
    "    set_seed(0)\n",
    "\n",
    "    cfg = Cfg()\n",
    "    cfg.context_s = float(args.context_s)\n",
    "    cfg.horizon_s = float(args.horizon_ms) / 1000.0\n",
    "\n",
    "    logger.info(f\"USING amp_min/amp_max: {cfg.amp_min:.3e} / {cfg.amp_max:.3e} | n_bins={cfg.n_bins}\")\n",
    "\n",
    "    if args.epochs is not None:\n",
    "        cfg.epochs = int(args.epochs)\n",
    "    if args.filters is not None:\n",
    "        cfg.n_filters = int(args.filters)\n",
    "    if args.lr is not None:\n",
    "        cfg.lr = float(args.lr)\n",
    "\n",
    "    dils = dilations_1s_context()\n",
    "    cfg.receptive_field = int(receptive_field(cfg.kernel_size, dils))\n",
    "    logger.info(\n",
    "        f\"Architecture: k={cfg.kernel_size}, \"\n",
    "        f\"layers={len(dils)}, \"\n",
    "        f\"RF={cfg.receptive_field} samples \"\n",
    "        f\"({cfg.receptive_field/cfg.sfreq:.3f}s)\"\n",
    "    )\n",
    "\n",
    "    logger.info(\"LOAD DATA...\")\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    epochs_1d = load_epochs_from_npz(config[\"data_preparation\"][\"npz_data_output\"])\n",
    "    N = len(epochs_1d)\n",
    "    logger.info(f\"sfreq={cfg.sfreq} | n_epochs={N} | load_dt={time.perf_counter()-t0:.2f}s\")\n",
    "\n",
    "    train_ids, val_ids, test_ids = split_epochs(\n",
    "        N, train_frac=args.train_frac, val_frac=args.val_frac, seed=args.split_seed\n",
    "    )\n",
    "    tr_list = [epochs_1d[int(i)] for i in train_ids]\n",
    "    va_list_full = [epochs_1d[int(i)] for i in val_ids]\n",
    "    te_list_full = [epochs_1d[int(i)] for i in test_ids]\n",
    "\n",
    "    logger.info(f\"splits (uLAR-style): train={len(tr_list)} val={len(va_list_full)} test={len(te_list_full)}\")\n",
    "\n",
    "    max_eval = int(args.eval_max_epochs) if args.eval_max_epochs is not None else None\n",
    "    va_list = va_list_full[:max_eval] if max_eval is not None else va_list_full\n",
    "    te_list = te_list_full[:max_eval] if max_eval is not None else te_list_full\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logger.info(f\"device={device}\")\n",
    "\n",
    "    run_name = f\"consumption-h{args.horizon_ms:.0f}ms\"\n",
    "    wb = wandb_init(asdict(cfg), run_name=run_name)\n",
    "\n",
    "    model = WaveNetCategorical(n_bins=cfg.n_bins, n_filters=cfg.n_filters, kernel_size=cfg.kernel_size)\n",
    "\n",
    "    if args.ckpt is not None:\n",
    "        bundle = torch.load(args.ckpt, map_location=\"cpu\", weights_only=False)\n",
    "        if isinstance(bundle, dict) and \"model\" in bundle:\n",
    "            model.load_state_dict(bundle[\"model\"])\n",
    "        else:\n",
    "            model.load_state_dict(bundle)\n",
    "        logger.info(f\"Loaded checkpoint: {args.ckpt}\")\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            logger.info(f\"[GPU CHECK] cuda mem allocated MB={torch.cuda.memory_allocated()/1024**2:.1f}\")\n",
    "\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    if not args.eval_only:\n",
    "        ckpt_dir = out_dir / \"checkpoints\"\n",
    "\n",
    "        train_ds = RandomWaveNetSegments(\n",
    "            epochs_1d=tr_list,\n",
    "            seq_len=cfg.seq_len,\n",
    "            n_samples=cfg.train_samples_per_epoch,\n",
    "            amp_min=cfg.amp_min,\n",
    "            amp_max=cfg.amp_max,\n",
    "            n_bins=cfg.n_bins,\n",
    "            rng=np.random.default_rng(1),\n",
    "        )\n",
    "\n",
    "        ys = []\n",
    "        for i in range(10):\n",
    "            _, y0 = train_ds[i]\n",
    "            ys.append(y0)\n",
    "        ycat = torch.cat(ys)\n",
    "        logger.info(\n",
    "            f\"DEBUG train_ds bins: unique={int(torch.unique(ycat).numel())} \"\n",
    "            f\"minbin={int(ycat.min())} maxbin={int(ycat.max())}\"\n",
    "        )\n",
    "\n",
    "\n",
    "        val_ds_tmp = RandomWaveNetSegments(\n",
    "            epochs_1d=va_list_full,\n",
    "            seq_len=cfg.seq_len,\n",
    "            n_samples=cfg.val_samples_fixed,\n",
    "            amp_min=cfg.amp_min,\n",
    "            amp_max=cfg.amp_max,\n",
    "            n_bins=cfg.n_bins,\n",
    "            rng=np.random.default_rng(2),\n",
    "        )\n",
    "        fixed_pairs = list(val_ds_tmp.pairs)\n",
    "        val_ds = RandomWaveNetSegments(\n",
    "            epochs_1d=va_list_full,\n",
    "            seq_len=cfg.seq_len,\n",
    "            n_samples=len(fixed_pairs),\n",
    "            amp_min=cfg.amp_min,\n",
    "            amp_max=cfg.amp_max,\n",
    "            n_bins=cfg.n_bins,\n",
    "            rng=np.random.default_rng(2),\n",
    "            fixed_pairs=fixed_pairs,\n",
    "        )\n",
    "        val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=0, drop_last=False)\n",
    "\n",
    "\n",
    "        rf = cfg.receptive_field\n",
    "        counts = torch.zeros(cfg.n_bins, dtype=torch.long)\n",
    "        total = 0\n",
    "        for _, yb in val_loader:\n",
    "            y_v = yb[:, rf:].reshape(-1)  # ignora i primi rf come fai in training\n",
    "            counts += torch.bincount(y_v.cpu(), minlength=cfg.n_bins)\n",
    "            total += int(y_v.numel())\n",
    "        p = counts.float() / max(total, 1)\n",
    "        unigram_ce = (-(p.clamp_min(1e-12).log()) * counts.float()).sum() / max(total, 1)\n",
    "        logger.info(f\"BASELINE val_unigram_ce={unigram_ce.item():.6e} (lower is better)\")\n",
    "\n",
    "\n",
    "        logger.info(f\"Checkpoints: {ckpt_dir}\")\n",
    "        logger.info(f\"TRAIN for up to {cfg.epochs} epochs...\")\n",
    "\n",
    "        model = train_model(\n",
    "            model=model,\n",
    "            train_ds=train_ds,\n",
    "            val_loader=val_loader,\n",
    "            rf=cfg.receptive_field,\n",
    "            cfg=cfg,\n",
    "            device=device,\n",
    "            logger=logger,\n",
    "            wb_run=wb,\n",
    "            ckpt_dir=ckpt_dir,\n",
    "        )\n",
    "\n",
    "        torch.save({\"model\": model.state_dict(), \"cfg\": asdict(cfg)}, out_dir / \"final.pt\")\n",
    "        logger.info(f\"Saved: {out_dir/'final.pt'}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    logger.info(\n",
    "        f\"EVAL: {args.horizon_ms:.0f}ms post-cue window using {cfg.context_s:.1f}s pre-cue context...\"\n",
    "    )\n",
    "    m_val = eval_postcue_window(model, va_list, cfg, device, decode=args.decode)\n",
    "    m_test = eval_postcue_window(model, te_list, cfg, device, decode=args.decode)\n",
    "    logger.info(f\"VAL {args.horizon_ms:.0f}ms-postcue:  {m_val}\")\n",
    "    logger.info(f\"TEST {args.horizon_ms:.0f}ms-postcue: {m_test}\")\n",
    "\n",
    "    save_random_postcue_plots(\n",
    "        model=model,\n",
    "        epochs_1d=te_list,\n",
    "        cfg=cfg,\n",
    "        device=device,\n",
    "        out_dir=out_dir,\n",
    "        n_plots=10,\n",
    "        split_name=\"test\",\n",
    "        seed=0,\n",
    "    )\n",
    "    logger.info(f\"Saved 10 random post-cue plots to: {out_dir}\")\n",
    "\n",
    "    (out_dir / f\"val_metrics_{int(round(args.horizon_ms))}ms_postcue.json\").write_text(json.dumps(m_val, indent=2))\n",
    "    (out_dir / f\"test_metrics_{int(round(args.horizon_ms))}ms_postcue.json\").write_text(json.dumps(m_test, indent=2))\n",
    "\n",
    "    if wb is not None:\n",
    "        wb.log({f\"val_postcue/{k}\": float(v) for k, v in m_val.items() if k != \"N\"})\n",
    "        wb.log({f\"test_postcue/{k}\": float(v) for k, v in m_test.items() if k != \"N\"})\n",
    "\n",
    "    if not args.no_stream_eval:\n",
    "        logger.info(\n",
    "            f\"EVAL: STREAMING latency-comp (predict x(t+{args.horizon_ms:.0f}ms) for many t) | post_cue_s={args.stream_post_cue_s} | step_ms={args.stream_step_ms}\"\n",
    "        )\n",
    "        m_val_s = eval_streaming_latency_comp(\n",
    "            model,\n",
    "            va_list,\n",
    "            cfg,\n",
    "            device,\n",
    "            decode=args.decode,\n",
    "            post_cue_s=float(args.stream_post_cue_s),\n",
    "            step_ms=float(args.stream_step_ms),\n",
    "            max_epochs=max_eval,\n",
    "        )\n",
    "        m_test_s = eval_streaming_latency_comp(\n",
    "            model,\n",
    "            te_list,\n",
    "            cfg,\n",
    "            device,\n",
    "            decode=args.decode,\n",
    "            post_cue_s=float(args.stream_post_cue_s),\n",
    "            step_ms=float(args.stream_step_ms),\n",
    "            max_epochs=max_eval,\n",
    "        )\n",
    "        logger.info(f\"VAL streaming {args.horizon_ms:.0f}ms-ahead:  {m_val_s}\")\n",
    "        logger.info(f\"TEST streaming {args.horizon_ms:.0f}ms-ahead: {m_test_s}\")\n",
    "\n",
    "        (out_dir / f\"val_stream_{int(round(args.horizon_ms))}ms_step{int(round(args.stream_step_ms))}ms.json\").write_text(\n",
    "            json.dumps(m_val_s, indent=2)\n",
    "        )\n",
    "        (out_dir / f\"test_stream_{int(round(args.horizon_ms))}ms_step{int(round(args.stream_step_ms))}ms.json\").write_text(\n",
    "            json.dumps(m_test_s, indent=2)\n",
    "        )\n",
    "\n",
    "        if wb is not None:\n",
    "            wb.log({f\"val_stream/{k}\": float(v) for k, v in m_val_s.items() if k != \"N\"})\n",
    "            wb.log({f\"test_stream/{k}\": float(v) for k, v in m_test_s.items() if k != \"N\"})\n",
    "\n",
    "    if wb is not None:\n",
    "        wb.finish()\n",
    "\n",
    "    logger.info(\"DONE\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
