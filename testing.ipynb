{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-22T03:00:20.316925Z",
     "start_time": "2026-02-22T03:00:20.171923Z"
    }
   },
   "source": [
    "import argparse\n",
    "from dataclasses import asdict\n",
    "import time\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from core.wavenet import WaveNetCategorical\n",
    "from util.metrics import save_random_postcue_plots\n",
    "from util.util import *\n",
    "from util.datasets import RandomWaveNetSegments\n",
    "from util.Cfg import Cfg\n",
    "from util.wavenet import dilations_1s_context, receptive_field\n",
    "from core.training import train_model, eval_streaming_latency_comp, eval_postcue_window\n",
    "\n",
    "import yaml\n",
    "\n",
    "config = yaml.safe_load(open(\"config.yaml\"))\n",
    "\n",
    "def main():\n",
    "\n",
    "    args = Cfg()\n",
    "\n",
    "    out_dir = Path.cwd() / config[\"training\"][\"out_dir\"]\n",
    "    logger = setup_logger(out_dir)\n",
    "    set_seed(0)\n",
    "\n",
    "    cfg = Cfg()\n",
    "\n",
    "    logger.info(f\"USING amp_min/amp_max: {cfg.amp_min:.3e} / {cfg.amp_max:.3e} | n_bins={cfg.n_bins}\")\n",
    "\n",
    "    dils = dilations_1s_context()\n",
    "    cfg.receptive_field = int(receptive_field(cfg.kernel_size, dils))\n",
    "    logger.info(\n",
    "        f\"Architecture: k={cfg.kernel_size}, \"\n",
    "        f\"layers={len(dils)}, \"\n",
    "        f\"RF={cfg.receptive_field} samples \"\n",
    "        f\"({cfg.receptive_field/cfg.sfreq:.3f}s)\"\n",
    "    )\n",
    "\n",
    "    logger.info(\"LOAD DATA...\")\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    epochs_1d = load_epochs_from_npz(config[\"data_preparation\"][\"npz_data_output\"])\n",
    "    N = len(epochs_1d)\n",
    "    logger.info(f\"sfreq={cfg.sfreq} | n_epochs={N} | load_dt={time.perf_counter()-t0:.2f}s\")\n",
    "\n",
    "    train_ids, val_ids, test_ids = split_epochs(\n",
    "        N, train_frac=args.train_frac, val_frac=args.val_frac, seed=args.split_seed\n",
    "    )\n",
    "    tr_list = [epochs_1d[int(i)] for i in train_ids]\n",
    "    va_list_full = [epochs_1d[int(i)] for i in val_ids]\n",
    "    te_list_full = [epochs_1d[int(i)] for i in test_ids]\n",
    "\n",
    "    logger.info(f\"splits (uLAR-style): train={len(tr_list)} val={len(va_list_full)} test={len(te_list_full)}\")\n",
    "\n",
    "    max_eval = int(args.eval_max_epochs) if args.eval_max_epochs is not None else None\n",
    "    va_list = va_list_full[:max_eval] if max_eval is not None else va_list_full\n",
    "    te_list = te_list_full[:max_eval] if max_eval is not None else te_list_full\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logger.info(f\"device={device}\")\n",
    "\n",
    "    run_name = f\"consumption-h{args.horizon_ms:.0f}ms\"\n",
    "    wb = wandb_init(asdict(cfg), run_name=run_name)\n",
    "\n",
    "    model = WaveNetCategorical(n_bins=cfg.n_bins, n_filters=cfg.n_filters, kernel_size=cfg.kernel_size)\n",
    "\n",
    "    if args.ckpt is not None:\n",
    "        bundle = torch.load(args.ckpt, map_location=\"cpu\", weights_only=False)\n",
    "        if isinstance(bundle, dict) and \"model\" in bundle:\n",
    "            model.load_state_dict(bundle[\"model\"])\n",
    "        else:\n",
    "            model.load_state_dict(bundle)\n",
    "        logger.info(f\"Loaded checkpoint: {args.ckpt}\")\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            logger.info(f\"[GPU CHECK] cuda mem allocated MB={torch.cuda.memory_allocated()/1024**2:.1f}\")\n",
    "\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    if not args.eval_only:\n",
    "        ckpt_dir = out_dir / \"checkpoints\"\n",
    "\n",
    "        train_ds = RandomWaveNetSegments(\n",
    "            epochs_1d=tr_list,\n",
    "            seq_len=cfg.seq_len,\n",
    "            n_samples=cfg.train_samples_per_epoch,\n",
    "            amp_min=cfg.amp_min,\n",
    "            amp_max=cfg.amp_max,\n",
    "            n_bins=cfg.n_bins,\n",
    "            rng=np.random.default_rng(1),\n",
    "        )\n",
    "\n",
    "        ys = []\n",
    "        for i in range(10):\n",
    "            _, y0 = train_ds[i]\n",
    "            ys.append(y0)\n",
    "        ycat = torch.cat(ys)\n",
    "        logger.info(\n",
    "            f\"DEBUG train_ds bins: unique={int(torch.unique(ycat).numel())} \"\n",
    "            f\"minbin={int(ycat.min())} maxbin={int(ycat.max())}\"\n",
    "        )\n",
    "\n",
    "\n",
    "        val_ds_tmp = RandomWaveNetSegments(\n",
    "            epochs_1d=va_list_full,\n",
    "            seq_len=cfg.seq_len,\n",
    "            n_samples=cfg.val_samples_fixed,\n",
    "            amp_min=cfg.amp_min,\n",
    "            amp_max=cfg.amp_max,\n",
    "            n_bins=cfg.n_bins,\n",
    "            rng=np.random.default_rng(2),\n",
    "        )\n",
    "        fixed_pairs = list(val_ds_tmp.pairs)\n",
    "        val_ds = RandomWaveNetSegments(\n",
    "            epochs_1d=va_list_full,\n",
    "            seq_len=cfg.seq_len,\n",
    "            n_samples=len(fixed_pairs),\n",
    "            amp_min=cfg.amp_min,\n",
    "            amp_max=cfg.amp_max,\n",
    "            n_bins=cfg.n_bins,\n",
    "            rng=np.random.default_rng(2),\n",
    "            fixed_pairs=fixed_pairs,\n",
    "        )\n",
    "        val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=0, drop_last=False)\n",
    "\n",
    "\n",
    "        rf = cfg.receptive_field\n",
    "        counts = torch.zeros(cfg.n_bins, dtype=torch.long)\n",
    "        total = 0\n",
    "        for _, yb in val_loader:\n",
    "            y_v = yb[:, rf:].reshape(-1)  # ignora i primi rf come fai in training\n",
    "            counts += torch.bincount(y_v.cpu(), minlength=cfg.n_bins)\n",
    "            total += int(y_v.numel())\n",
    "        p = counts.float() / max(total, 1)\n",
    "        unigram_ce = (-(p.clamp_min(1e-12).log()) * counts.float()).sum() / max(total, 1)\n",
    "        logger.info(f\"BASELINE val_unigram_ce={unigram_ce.item():.6e} (lower is better)\")\n",
    "\n",
    "\n",
    "        logger.info(f\"Checkpoints: {ckpt_dir}\")\n",
    "        logger.info(f\"TRAIN for up to {cfg.epochs} epochs...\")\n",
    "\n",
    "        model = train_model(\n",
    "            model=model,\n",
    "            train_ds=train_ds,\n",
    "            val_loader=val_loader,\n",
    "            rf=cfg.receptive_field,\n",
    "            cfg=cfg,\n",
    "            device=device,\n",
    "            logger=logger,\n",
    "            wb_run=wb,\n",
    "            ckpt_dir=ckpt_dir,\n",
    "        )\n",
    "\n",
    "        torch.save({\"model\": model.state_dict(), \"cfg\": asdict(cfg)}, out_dir / \"final.pt\")\n",
    "        logger.info(f\"Saved: {out_dir/'final.pt'}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    logger.info(\n",
    "        f\"EVAL: {args.horizon_ms:.0f}ms post-cue window using {cfg.context_s:.1f}s pre-cue context...\"\n",
    "    )\n",
    "    m_val = eval_postcue_window(model, va_list, cfg, device, decode=args.decode)\n",
    "    m_test = eval_postcue_window(model, te_list, cfg, device, decode=args.decode)\n",
    "    logger.info(f\"VAL {args.horizon_ms:.0f}ms-postcue:  {m_val}\")\n",
    "    logger.info(f\"TEST {args.horizon_ms:.0f}ms-postcue: {m_test}\")\n",
    "\n",
    "    save_random_postcue_plots(\n",
    "        model=model,\n",
    "        epochs_1d=te_list,\n",
    "        cfg=cfg,\n",
    "        device=device,\n",
    "        out_dir=out_dir,\n",
    "        n_plots=10,\n",
    "        split_name=\"test\",\n",
    "        seed=0,\n",
    "    )\n",
    "    logger.info(f\"Saved 10 random post-cue plots to: {out_dir}\")\n",
    "\n",
    "    (out_dir / f\"val_metrics_{int(round(args.horizon_ms))}ms_postcue.json\").write_text(json.dumps(m_val, indent=2))\n",
    "    (out_dir / f\"test_metrics_{int(round(args.horizon_ms))}ms_postcue.json\").write_text(json.dumps(m_test, indent=2))\n",
    "\n",
    "    if wb is not None:\n",
    "        wb.log({f\"val_postcue/{k}\": float(v) for k, v in m_val.items() if k != \"N\"})\n",
    "        wb.log({f\"test_postcue/{k}\": float(v) for k, v in m_test.items() if k != \"N\"})\n",
    "\n",
    "    if not args.no_stream_eval:\n",
    "        logger.info(\n",
    "            f\"EVAL: STREAMING latency-comp (predict x(t+{args.horizon_ms:.0f}ms) for many t) | post_cue_s={args.stream_post_cue_s} | step_ms={args.stream_step_ms}\"\n",
    "        )\n",
    "        m_val_s = eval_streaming_latency_comp(\n",
    "            model,\n",
    "            va_list,\n",
    "            cfg,\n",
    "            device,\n",
    "            decode=args.decode,\n",
    "            post_cue_s=float(args.stream_post_cue_s),\n",
    "            step_ms=float(args.stream_step_ms),\n",
    "            max_epochs=max_eval,\n",
    "        )\n",
    "        m_test_s = eval_streaming_latency_comp(\n",
    "            model,\n",
    "            te_list,\n",
    "            cfg,\n",
    "            device,\n",
    "            decode=args.decode,\n",
    "            post_cue_s=float(args.stream_post_cue_s),\n",
    "            step_ms=float(args.stream_step_ms),\n",
    "            max_epochs=max_eval,\n",
    "        )\n",
    "        logger.info(f\"VAL streaming {args.horizon_ms:.0f}ms-ahead:  {m_val_s}\")\n",
    "        logger.info(f\"TEST streaming {args.horizon_ms:.0f}ms-ahead: {m_test_s}\")\n",
    "\n",
    "        (out_dir / f\"val_stream_{int(round(args.horizon_ms))}ms_step{int(round(args.stream_step_ms))}ms.json\").write_text(\n",
    "            json.dumps(m_val_s, indent=2)\n",
    "        )\n",
    "        (out_dir / f\"test_stream_{int(round(args.horizon_ms))}ms_step{int(round(args.stream_step_ms))}ms.json\").write_text(\n",
    "            json.dumps(m_test_s, indent=2)\n",
    "        )\n",
    "\n",
    "        if wb is not None:\n",
    "            wb.log({f\"val_stream/{k}\": float(v) for k, v in m_val_s.items() if k != \"N\"})\n",
    "            wb.log({f\"test_stream/{k}\": float(v) for k, v in m_test_s.items() if k != \"N\"})\n",
    "\n",
    "    if wb is not None:\n",
    "        wb.finish()\n",
    "\n",
    "    logger.info(\"DONE\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-22 04:00:20,188] INFO - USING amp_min/amp_max: 0.000e+00 / 1.500e+01 | n_bins=256\n",
      "[2026-02-22 04:00:20,189] INFO - Architecture: k=2, layers=14, RF=1000 samples (1.000s)\n",
      "[2026-02-22 04:00:20,189] INFO - LOAD DATA...\n",
      "[2026-02-22 04:00:20,250] INFO - sfreq=1000.0 | n_epochs=270 | load_dt=0.06s\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Cfg' object has no attribute 'train_frac'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 233\u001B[39m\n\u001B[32m    229\u001B[39m     logger.info(\u001B[33m\"\u001B[39m\u001B[33mDONE\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    232\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m233\u001B[39m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 48\u001B[39m, in \u001B[36mmain\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     44\u001B[39m N = \u001B[38;5;28mlen\u001B[39m(epochs_1d)\n\u001B[32m     45\u001B[39m logger.info(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33msfreq=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcfg.sfreq\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m | n_epochs=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mN\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m | load_dt=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtime.perf_counter()-t0\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33ms\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     47\u001B[39m train_ids, val_ids, test_ids = split_epochs(\n\u001B[32m---> \u001B[39m\u001B[32m48\u001B[39m     N, train_frac=\u001B[43margs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain_frac\u001B[49m, val_frac=args.val_frac, seed=args.split_seed\n\u001B[32m     49\u001B[39m )\n\u001B[32m     50\u001B[39m tr_list = [epochs_1d[\u001B[38;5;28mint\u001B[39m(i)] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m train_ids]\n\u001B[32m     51\u001B[39m va_list_full = [epochs_1d[\u001B[38;5;28mint\u001B[39m(i)] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m val_ids]\n",
      "\u001B[31mAttributeError\u001B[39m: 'Cfg' object has no attribute 'train_frac'"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
